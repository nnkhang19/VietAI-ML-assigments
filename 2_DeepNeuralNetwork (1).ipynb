{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"2_DeepNeuralNetwork.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jAY-HQLVVK05"},"source":["## Assignment 2: Deep Neural Network \n"]},{"cell_type":"markdown","metadata":{"id":"fciXmk4mVK06"},"source":["### Giới thiệu\n","\n","Để có thể hoàn tất bài tập này, các bạn cần nắm rõ những kiến thức sau:\n","\n","    - Neural Networks - Fully connected networks là gì, nguyên tắc hoạt động ra sao.\n","\t- Giải thuật Feedforward và BackPropagation trong bài toán NN.\n","\t- Giải thuật gradient descent - Batch and Mini-batch.\n","\t- Regularization để tránh overfitting trong NN.\n","\n","Các bạn có thể tham khảo lại bài giảng của lớp để nắm vững các nội dung này. Ngoài ra, các bạn có thể đặt câu hỏi cho đội ngũ giảng dạy nếu có thắc mắc. \n","\n","Trong bài tập này các bạn sẽ sử dụng Neural Networks để giải quyết 2 bài toán:\n","\n","\t- Bài 1: phân loại dữ liệu BAT, gồm 3 lớp.\n","![Dữ liệu 3 class BAT](https://i.imgur.com/d1Pd1XT.png)\n","\t- Bài 2: phân loại tập fashion MNIST, gồm 10 lớp.\n","![Dữ liệu Fashion MNIST](https://i.imgur.com/O9dqdId.png)\n","Yêu cầu dành cho các bạn trong là giải quyết hai bài trên bằng Numpy và TensorFlow.\n","\n","Mục tiêu của bài tập lần này là hiện thực Neural Networks mạng Fully Connected một cách cơ bản trên Numpy và Tensorflow. Một mạng cơ bản sẽ gồm nhiều hidden layers và một lớp softmax tại layer cuối cùng phù hợp cho việc phân loại dữ liệu. \n","\n","![Mạng neural network. Nguồn: graphicsminer.com/neuralnetwork](https://i.imgur.com/K3Yvt20.png)\n","\n","Khi thiết kế một mạng cơ bản thì người dùng có thể quyết định số input feature cho tầng input. Số output sẽ là số lớp mà người đó muốn phân loại. Ví dụ như bài toán fashion MNIST thì số feature đầu vào chính bằng số pixel của mỗi ảnh, số nút đầu ra sẽ bằng số lớp cần phân loại (10). Đối với số lượng hidden layer và số lượng nodes tương ứng, ta có thể tùy chọn.\n","\n","Một chú ý rất quan trọng là số nodes đầu ra của layer trước sẽ là số inputs đầu vào của layers sau đó.\n"]},{"cell_type":"markdown","metadata":{"id":"rPH8uEJCVK07"},"source":["## I. Thực hiện Deep Neural Network với Numpy\n","### Những công việc bạn phải thực hiện \n","\n","1. Các hàm activation `sigmoid`, `tanh`, `relu`, `softmax` và đạo hàm của nó `sigmoid_grad`, `tanh_grad`, `relu_grad`.\n","2. Hàm `forward` và `backward` ở class `HiddenLayer`\n","```python\n","    class HiddenLayer:\n","    \n","        def forward(self, X):\n","            ...\n","    \n","        def backward(self, X, delta_prev):\n","            ...\n","```\n","3. Hàm `forward`, `backward`, `compute_loss` ở class `NeuralNetwork`\n","```python\n","    class NeuralNetwork:\n","        \n","        def forward(self, X):\n","            ...\n","            \n","        def backward(self, X, Y, layers):\n","            ...\n","            \n","        def compute_loss(self, Y, Y_hat):\n","            ...\n","```"]},{"cell_type":"markdown","metadata":{"id":"TohoN6f1VK07"},"source":["### Ký hiệu\n","\n","- $L$: số layers trong mạng neural network. \n","- $l = 0,1,..,L$ với $0$ là layer input và $L$ layer output.\n","- $n^{[l]}$ là số neurons tại layer $l$\n","- $l-1$: layer trước theo chiều forward của $l$.\n","- $l+1$: layer trước theo chiều backward của $l$.\n","- $\\sigma'(x)$: đạo hàm hàm activation theo x (general case cho cả đạo hàm sigmoid, tanh, relu).\n","- $Z^{[l]}$: linear function values tại layer $l$.\n","- $A^{[l]}$: activation function values tại layer $l$."]},{"cell_type":"markdown","metadata":{"id":"dneL9wNuVK08"},"source":["### Import các thư viện cần thiết"]},{"cell_type":"markdown","metadata":{"id":"He9JhemNND3D"},"source":["**Chú ý:** Nếu bạn chạy trên Google Colab thì các thư viện này đã được tích hợp sẵn. Nếu bạn chạy trên máy cá nhân, bạn cần install các thư viện *numpy*, *matplotlib*, *googledrivedownloader*, *sklearn*."]},{"cell_type":"code","metadata":{"id":"z5pqVHsNVK08","executionInfo":{"status":"ok","timestamp":1611368310124,"user_tz":-420,"elapsed":2119,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}}},"source":["%matplotlib inline\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython import display\n","from google_drive_downloader import GoogleDriveDownloader as gdd\n","import os\n","import sys\n","from sklearn.metrics import confusion_matrix"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qGdoufr7VK0-"},"source":["### Download dữ liệu và các utility functions"]},{"cell_type":"code","metadata":{"id":"2GG7Zj3aVK0_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611368316469,"user_tz":-420,"elapsed":3559,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}},"outputId":"0900d2d6-c682-477f-bd76-2e4df41180e6"},"source":["# DOWNLOAD DATA\n","gdd.download_file_from_google_drive(file_id='1EXSdvCLlcXvl1Gi6sNSJCu6psICoLNNc', \n","                                    dest_path=os.path.join(os.getcwd(), 'Assignment2.zip'), unzip=True)\n","\n","if sys.platform.startswith(\"win\"):\n","    !move \"./Assignment2/data\" \".\"\n","    !move \"./Assignment2/test\" \".\"A\n","    !move \"./Assignment2/utils\" \".\"\n","    !del \"Assignment2.zip\"\n","    !rd /s /q \"Assignment2\" \"__MACOSX\"\n","    !dir\n","else:\n","    !mv Assignment2/* .\n","    !rm Assignment2.zip\n","    !rm -rf Assignment2 __MACOSX\n","    # SHOW THE ITEMS OF CURRENT DIRRECTORY\n","    !ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Downloading 1EXSdvCLlcXvl1Gi6sNSJCu6psICoLNNc into /content/Assignment2.zip... Done.\n","Unzipping...Done.\n","data  sample_data  test  utils\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UsUETR3AVixy"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ctdckAhpYkqf"},"source":["### Import utility functions"]},{"cell_type":"code","metadata":{"id":"sJeV7fvvYtl1","executionInfo":{"status":"ok","timestamp":1611368320101,"user_tz":-420,"elapsed":1353,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}}},"source":["from utils.util import *\n","from utils.gradient_check import *"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVLd-jBpVK1B"},"source":["### Các hàm activation\n","\n","$$sigmoid(x) = \\frac{1}{1+e^{-x}}$$ \n","\n","$$tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}} $$\n","\n","$$relu(x) = \\begin{cases} x, & \\mbox{if } x > 0 \\\\ 0, & \\mbox{if } x <= 0 \\end{cases}$$\n","\n","$$sigmoid'(x) = sigmoid(x)(1 - sigmoid(x)) $$\n","\n","$$tanh'(x) = 1 - tanh^2(x)$$\n","\n","$$relu'(x) = \\begin{cases} 1, & \\mbox{if } x > 0 \\\\ 0, & \\mbox{if } x <= 0 \\end{cases}$$"]},{"cell_type":"markdown","metadata":{"id":"uQxzv26Lo1a_"},"source":["#### \\[TODO 1\\] Cài đặt các hàm activation\n","Định nghĩa các hàm activation ở cell bên dưới. (1đ)"]},{"cell_type":"code","metadata":{"id":"hI_pLSHVVK1C"},"source":["def sigmoid(x):\n","    \"\"\"\n","    Sigmoid function.\n","    :param x: input\n","    \"\"\"\n","    #### [TODO 1] START CODE HERE #### \n","    x = 1./(1 + np.exp(-x))\n","    #### END CODE HERE ####\n","    return x\n","\n","\n","def sigmoid_grad(x):\n","    \"\"\"\n","    Compute gradient of sigmoid.\n","    :param x: input\n","    \"\"\"\n","    \n","    #### [TODO 1] START CODE HERE #### \n","    da = sigmoid(x) * ( 1 - sigmoid(x))\n","    #### END CODE HERE ####\n","    return da\n","\n","\n","def relu(x):\n","    \"\"\"\n","    Rectified linear unit function.\n","    :param x: input\n","    \"\"\"\n","    \n","    #### [TODO 1] START CODE HERE #### \n","    x = np.where(x > 0, x, 0)\n","    #### END CODE HERE ####\n","    return x\n","\n","\n","def relu_grad(x):\n","    \"\"\"\n","    Compute gradient of ReLU.\n","    :param x: input\n","    \"\"\"\n","    \n","    #### [TODO 1] START CODE HERE #### \n","    da = np.where(x > 0, 1, 0)\n","    #### END CODE HERE ####\n","    return da\n","\n","\n","def tanh(x):\n","    \"\"\"\n","    Tanh function.\n","    :param x: input\n","    \"\"\"\n","   \n","    #### [TODO 1] START CODE HERE #### \n","    x = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n","    #### END CODE HERE ####\n","    return x\n","\n","\n","def tanh_grad(x):\n","    \"\"\"\n","    Compute gradient for tanh.\n","    :param x: input\n","    \"\"\"\n","\n","    #### [TODO 1] START CODE HERE ####\n","    da =  1 - tanh(x) ** 2\n","    #### END CODE HERE ####\n","    return da\n","\n","def softmax(x):\n","    \"\"\"\n","    Stable softmax function.\n","    :param x: input\n","    \"\"\"\n","    #### [TODO 1] START CODE HERE ####\n","    z_max = np.amax(x,axis =  1, keepdims = True)\n","    z_max = np.exp(x - z_max)\n","    probs= np.sum(z_max,axis = 1, keepdims = True)\n","    probs = z_max / probs   \n","    #### END CODE HERE ####\n","    return probs "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0c92wODTVK1E"},"source":["#### Kiểm tra lại lại các hàm activation đã cài đặt\n","\n","Bạn có thể kiểm tra cái hàm bạn đã cài đặt bằng đoạn code bên dưới."]},{"cell_type":"code","metadata":{"id":"Neen94acVK1E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611317926586,"user_tz":-420,"elapsed":759,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}},"outputId":"af60dd89-16d6-4780-a0bb-1c01c92f224e"},"source":["import pickle\n","\n","np.random.seed(2019)\n","func_test = [\"sigmoid\", \"relu\", \"tanh\", \"sigmoid_grad\", \"relu_grad\", \"tanh_grad\", \"softmax\"]\n","test_activation = dict()\n","results = []\n","with open(\"test/activation.pkl\", \"rb\") as f:\n","    test_activation = pickle.load(f)\n","\n","test_x = test_activation[\"test_x\"]\n","sample = test_activation[\"sample\"]\n","\n","for i, func_str in enumerate(func_test):\n","    func = eval(func_str)\n","    if func(test_x) is None:\n","        results.append(func_str)\n","        continue\n","    sample.append(func(test_x))\n","    if not np.allclose(func(test_x), sample[i]):\n","          results.append(func_str)\n","\n","if len(results) == 0:\n","    print(\"Test PASS!\")\n","else:\n","    print(\"Test FAILED: \" + \", \".join(results))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test PASS!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VZTlOP46VK1G"},"source":["### Class `HiddenLayer` \n","\n","#### Hướng dẫn:\n","\n","1. Hàm `forward`:\n","- Hàm nhận vào tham số input $X$ (là output của hidden layer trước theo chiều forward, layer $l-1$).\n","- Tính linear transformation của $X$ ($A^{[l-1]}$): $Z^{[l]} = XW$.\n","- Sau đó tính nonlinear transformation: $A^{[l]} = \\sigma(Z^{[l]})$ với $\\sigma$ là hàm activation.\n","    \n","2. Hàm `backward`:\n","- Hàm nhận vào 2 tham số input `X`(là output của hidden layer trước đó theo chiều forward) với `delta_prev` (delta trước đó theo chiều backward).\n","- Tính delta tại layer $l$: \n","    \n","    $$\\delta^{[l]} = \\frac{\\partial J}{\\partial A^{[l]}}\\frac{\\partial A^{[l]}}{\\partial Z^{[l]}} =  \\delta^{[l+1]} * \\sigma'(Z^{[l]})$$ \n","\n","Chú ý: $*$ operation là element-wise multiplication.\n","- Tính W_grad (without regularization): $\\nabla W^{[l]} = (A^{[l-1]})^T\\delta^{[l]} $\n","- With regularization:  $\\nabla W^{[l]} = (A^{[l-1]})^T\\delta^{[l]} + \\frac{\\lambda}{m} W^{[l]}$ với $\\lambda$ là hệ số regularization (hyperparameter mình sẽ chọn)."]},{"cell_type":"markdown","metadata":{"id":"qfSLDffVYQdc"},"source":["#### \\[TODO 2\\] Hàm `forward`\n","Định nghĩa hàm `forward` trong class `HiddenLayer` (1đ)"]},{"cell_type":"markdown","metadata":{"id":"d4uUr2FKh97J"},"source":["#### \\[TODO 3\\] Hàm `backward` \n","Định nghĩa hàm `backward` trong class `HiddenLayer` (2đ)\n","  + Tính W_grad (without regularization) (1đ)\n","  + Tính W_grad (with L2 regularization) (1đ)"]},{"cell_type":"code","metadata":{"id":"eROUmEreVK1H"},"source":["class HiddenLayer:\n","    \"\"\"\n","    Abstract hidden layer used in Neural Network.\n","    \"\"\"\n","    \n","    def __init__(self, num_neurons, activation, reg = 0.0):\n","        \"\"\"\n","        Constructor for abstract hidden layer.\n","        \n","        Parameters\n","        ----------\n","        num_neurons: (integer) specify number of neurons in this layer.\n","        activation: (string) indicating which activation function to be used.  \n","                        the string must be in [\"sigmoid\", \"relu\", \"tanh\", \"softmax\"]\n","        reg: (float) regularization coefficient to help with overfitting.\n","        \"\"\"\n","        assert activation in [\"sigmoid\", \"relu\", \"tanh\", \"softmax\"], \"Activation must be in [sigmoid, relu, tanh, softmax]\"\n","        self.num_neurons = num_neurons\n","        self.W = None \n","        self.activation = activation\n","        self.reg = reg\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Compute nonlinear function of input X.\n","            X -> LINEAR -> ACTIVATION.\n","            \n","        `activation_function` variable below is equal to this piece of code:\n","        \n","            if (self.activation == 'sigmoid'):\n","                activation_function = sigmoid\n","            elif (self.activation == 'relu'):\n","                activation_function = reLU\n","            elif (self.activation == 'tanh'):\n","                activation_function = tanh\n","            elif (self.activation == 'softmax'):\n","                activation_function = softmax\n","        \n","        Parameters\n","        ----------\n","        X: output of the previous layer (input for the current layer).\n","        \n","        Returns\n","        -------\n","        A: output of the current layer.\n","        \"\"\"\n","        if self.W is None:\n","            W_shape = (X.shape[1], self.num_neurons)\n","            self.W = np.random.normal(0, np.sqrt(2/(X.shape[1]+self.num_neurons)), W_shape)\n","        \n","        activation_function = eval(self.activation) # this returns function variable\n","        \n","        #### [TODO 2] START CODE HERE ####\n","        self.Z = X @ self.W\n","        A = activation_function(self.Z) # use `activation_function` function above apply to `Z`\n","        #### END CODE HERE ####\n","        return A\n","\n","    def backward(self, X, delta_prev):\n","        \"\"\"\n","        Compute gradient w.r.t X and W at the current layer.\n","            X <- LINEAR <- ACTIVATION.\n","            W <- LINEAR <- ACTIVATION.\n","        \n","        Parameters\n","        ----------\n","        X: output of the previous layer (input for the current layer).\n","        delta_prev: delta dot product with W computed from the next layer (in feedforward direction) \n","                                or previous layer (in backpropagation direction)\n","        \"\"\"\n","        activation_grad_function = eval(self.activation + \"_grad\")\n","        z = self.Z\n","\n","        #### [TODO 3] START CODE HERE ####                                \n","        delta = delta_prev * activation_grad_function(z)\n","        W_grad = X.T @ delta  # without regularization\n","        #### END CODE HERE ####\n","\n","        #### [TODO 3] START CODE HERE ####                             \n","        W_grad += (self.W * self.reg) / len(X) # with L2 regularization\n","        #### END CODE HERE ####\n","        \n","        return W_grad, delta"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LKWbE4ESVK1I"},"source":["#### Kiểm tra class `HiddenLayer` được cài đặt\n","\n","Sau khi hoàn thành TODO 2 và TODO 3, bạn có thể kiểm tra class `HiddenLayer` bạn đã cài đặt bằng cách chạy cell bên dưới:"]},{"cell_type":"code","metadata":{"id":"vUZJGVMuVK1J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611317976452,"user_tz":-420,"elapsed":732,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}},"outputId":"d95d780f-2060-46a4-b5ca-05baeb4d8907"},"source":["np.random.seed(2019)\n","case_1 = HiddenLayer(10, \"sigmoid\", reg=0)\n","case_2 = HiddenLayer(14, \"tanh\", reg=0)\n","case_3 = HiddenLayer(17, \"relu\", reg=0)\n","\n","case_mapping = {0: \"(foward)\", 1: \"(backward W_grad)\", 2: \"(backward delta)\"}\n","\n","with open(\"test/hidden.pkl\", \"rb\") as f:\n","    test_hidden = pickle.load(f)\n","\n","test_x = test_hidden[\"test_x\"]\n","sample = test_hidden[\"sample\"]\n","test_delta = test_hidden[\"test_delta\"]\n","results = []\n","for ind, cl_str in enumerate([\"case_1\", \"case_2\", \"case_3\"]):\n","    hidden_layer = eval(cl_str)\n","    case = (hidden_layer.forward(test_x), ) + hidden_layer.backward(test_x, test_delta[ind])\n","    for i in range(3):\n","        if not np.allclose(sample[ind][i], case[i]):\n","            results.append(cl_str + case_mapping[i])\n","\n","print(\"TEST HiddenLayer WITHOUT REGULARIZATION\")\n","if len(results) == 0:\n","    print(\"Test PASS!\")\n","else:\n","    print(\"Test FAILED: \" + \", \".join(results))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TEST HiddenLayer WITHOUT REGULARIZATION\n","Test PASS!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t3490b6mfJwM"},"source":["Các bạn nên chắc chắn rằng mình đã pass hết các test cases để làm tiếp."]},{"cell_type":"markdown","metadata":{"id":"P8HSsFNGfMqi"},"source":["#### Kiểm tra Hidden Layer với Regularization\n","\n","Các bạn có thể bỏ qua phần test case này nếu chưa làm với Regularization."]},{"cell_type":"code","metadata":{"id":"dYsQBucQfQWq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611317978901,"user_tz":-420,"elapsed":725,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}},"outputId":"0fce01c7-498e-4f6d-8114-b5329ff59353"},"source":["np.random.seed(2019)\n","case_1 = HiddenLayer(10, \"sigmoid\", reg=0.9)\n","case_2 = HiddenLayer(14, \"tanh\", reg=0.9)\n","case_3 = HiddenLayer(17, \"relu\", reg=0.9)\n","\n","case_mapping = {0: \"(foward)\", 1: \"(backward W_grad)\", 2: \"(backward delta)\"}\n","\n","with open(\"test/hidden_reg.pkl\", \"rb\") as f:\n","    test_hidden = pickle.load(f)\n","\n","test_x = test_hidden[\"test_x\"]\n","sample = test_hidden[\"sample\"]\n","test_delta = test_hidden[\"test_delta\"]\n","results = []\n","for ind, cl_str in enumerate([\"case_1\", \"case_2\", \"case_3\"]):\n","    hidden_layer = eval(cl_str)\n","    case = (hidden_layer.forward(test_x), ) + hidden_layer.backward(test_x, test_delta[ind])\n","    for i in range(3):\n","        if not np.allclose(sample[ind][i], case[i]):\n","            results.append(cl_str + case_mapping[i])\n","\n","print(\"TEST HiddenLayer WITH REGULARIZATION\")\n","if len(results) == 0:\n","    print(\"Test PASS!\")\n","else:\n","    print(\"Test FAILED: \" + \", \".join(results))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TEST HiddenLayer WITH REGULARIZATION\n","Test PASS!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LRqpw1yWVK1K"},"source":["### Class `NeuralNetwork`\n","\n","#### Hướng dẫn:\n","\n","1. Hàm `forward`:\n","- Sử dụng hàm `forward` class `HiddenLayer`. Output của layer này [$l$] sẽ là input của layer sau [$l+1$]. Thêm output của layer [$l$] vào list `all_X` \n","\n","\n","2. Hàm `compute_loss`:\n","- Cross-entropy, không regularization: $$J = -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^C y_{ik}\\log(a_{ik}^{[L]})$$\n","- Cross-entropy, L2 regularization: $$J = -\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^C y_{ik}\\log(a_{ik}^{[L]}) + \\frac{\\lambda}{2m}\\sum_{l=1}^L\\|\\mathbf{W}^{[l]} \\|_2^2$$\n","    \n","    \n","3. Hàm `backward`:\n","\n","- Tính `delta_last` $\\delta^{[L]} $ và `grad_last` $\\nabla W^{[L]}$ theo hàm softmax (để ý superscript [L]): \n","    \n","    $$\\delta^{[L]} = \\frac{\\partial J}{\\partial \\mathbf{A}^{[L]}}\\frac{\\partial \\mathbf{A}^{[L]}}{\\partial \\mathbf{Z}^{[L]}} = \\frac{1}{m} (\\mathbf{A}^{[L]} - \\mathbf{Y})$$\n","\n","    - **Without regularization:**\n","        \n","        $$\\nabla W^{[L]} = \\frac{\\partial J}{\\partial \\mathbf{A}^{[L]}}\\frac{\\partial \\mathbf{A}^{[L]}}{\\partial \\mathbf{Z}^{[L]}}\\frac{\\partial \\mathbf{Z}^{[L]}}{\\partial \\mathbf{W}^{[L]}} = \\delta^{[L]} \\frac{\\partial \\mathbf{Z}^{[L]}}{\\partial \\mathbf{W}^{[L]}} = (\\mathbf{A}^{[L-1]})^T \\delta^{[L]} $$\n","\n","    - **With L2 regularization:**\n","\n","        $$\\nabla \\mathbf{W}^{[L]} = (\\mathbf{A}^{[L-1]})^T \\delta^{[L]} + \\frac{\\lambda}{m} W^{[l]}$$\n","\n","- Tính `delta_prev` $\\delta^{[l]}$ và `grad_W` $\\nabla \\mathbf{W}^{[l]}$ ở các tầng ở giữa:\n","    \n","    $$\\delta^{[l]} = \\left(\\delta^{[l+1]}(\\mathbf{W}^{[l+1]})^T\\right) * \\sigma'(\\mathbf{Z^{[l]}})$$\n","    \n","    - **Without regularization**\n","        \n","        $$\\nabla \\mathbf{W}^{[l]} = (\\mathbf{A}^{[l-1]})^T \\delta^{[l]}$$\n","\n","    - **With L2 regularization**\n","\n","        $$\\nabla \\mathbf{W}^{[l]} = (\\mathbf{A}^{[l-1]})^T \\delta^{[l]} + \\frac{\\lambda}{m} W^{[l]}$$\n","        \n","Mục đích tính `delta` để tính gradient của `W` ở các tầng trước theo chiều forward."]},{"cell_type":"markdown","metadata":{"id":"9sjTUfDesi3b"},"source":["#### \\[TODO 4\\] Hàm `forward`\n","Định nghĩa hàm `forward` trong class `NeuralNetwork` (0.5đ)"]},{"cell_type":"markdown","metadata":{"id":"TP4gB_yyjPoN"},"source":["#### \\[TODO 5\\] Hàm `compute_loss`\n","Định nghĩa hàm `compute_loss` trong class `NeuralNetwork` (1.5đ)\n","  + Loss without regularization\n","  + Loss of L2 regularization"]},{"cell_type":"markdown","metadata":{"id":"07CXsA6GjTXY"},"source":["#### \\[TODO 6\\] Hàm `compute_delta_grad_last`\n","Định nghĩa hàm `compute_delta_grad_last` trong class `NeuralNetwork` (1đ)\n","  + Without regularization (0.5đ)\n","  + With L2 regularization (0.5đ)"]},{"cell_type":"markdown","metadata":{"id":"JJjOZsXWjqz2"},"source":["#### [TODO 7] Hàm `backward`\n","Định nghĩa hàm `backward` trong class `NeuralNetwork` (1đ)"]},{"cell_type":"markdown","metadata":{"id":"Xv9USNyilQys"},"source":["#### \\[TODO 8\\] Hàm `update_weight_momentum`\n","Định nghĩa hàm `update_weight_momentum` trong class `NeuralNetwork`. (1đ)"]},{"cell_type":"code","metadata":{"id":"IqaUfUyZVK1L"},"source":["class NeuralNetwork:\n","    \n","    def __init__(self, learning_rate, num_class=2, reg = 1e-5):\n","        self.layers = []\n","        self.reg = reg\n","        self.num_class = num_class\n","        self.learning_rate = learning_rate\n","        \n","    def add_layer(self, num_neurons, activation):\n","        \"\"\"\n","        Function to add a hidden layer to neural network.\n","        \n","        Parameters\n","        ----------\n","        num_neurons: hyperparameter that specify nuber of neurons new hidden layer have/\n","        activation: string, indicating which activation function to be used\n","        \"\"\"\n","        assert activation in [\"sigmoid\", \"relu\", \"tanh\", \"softmax\"], \"Activation must be in [sigmoid, relu, tanh, softmax]\"\n","        self.layers.append(HiddenLayer(num_neurons, activation, self.reg))\n","\n","    def forward(self, X):\n","        \"\"\"\n","        Do forward propagation in the neural network\n","        \n","        Parameters\n","        ----------\n","        X: raw input X.\n","        \n","        Returns\n","        -------\n","        all_X: list of all X computed at each layer. \n","        \"\"\"\n","        all_X = [X]\n","        #### [TODO 4] START CODE HERE ####\n","        for i in range(len(self.layers)):\n","          X = self.layers[i].forward(X)\n","          all_X.append(X)\n","        #### END CODE HERE ####\n","        \n","        return all_X\n","    \n","    def compute_loss(self, Y, Y_hat):\n","        \"\"\"\n","        Compute the average cross entropy loss using Y (label) and Y_hat (predicted class)\n","                    and plus with regularization loss.\n","        Parameters\n","        ----------\n","        Y:  the label, the actual class of the samples. This is one-hot encoding vector.\n","                E.g: [0, 1, 2, 1] => [[1, 0, 0],\n","                                      [0, 1, 0],\n","                                      [0, 0, 1],\n","                                      [0, 1, 0]]\n","        Y_hat: the propabilities of classes (output of softmax).\n","        \n","        Returns\n","        -------\n","        \n","        \"\"\"\n","        #estimating cross entropy loss from y_hat and y\n","        #### [TODO 5] START CODE HERE ####\n","        m = len(Y)\n","        correct_log_probs = np.sum(Y * np.log(Y_hat), axis = 1) \n","        data_loss = -np.mean(correct_log_probs) # loss without regularization\n","        #### END CODE HERE ####\n","        #estimating regularization loss from all layers\n","        reg_loss = 0.0\n","        #### [TODO 5] START CODE HERE ####\n","        # compute reg_loss\n","        reg_loss = np.sum(self.reg * self.layers[-1].W) / m\n","        #### END CODE HERE ####\n","        data_loss += reg_loss # loss with L2 regularization\n","\n","        return data_loss\n","\n","    def compute_delta_grad_last(self, Y, all_X):\n","        \"\"\"\n","        Special formula to compute delta last and gradient last.\n","        \n","        Parameters\n","        ----------\n","        Y:  the label, the actual class of the samples. This is one-hot encoding vector.\n","                E.g: [0, 1, 2, 1] => [[1, 0, 0],\n","                                      [0, 1, 0],\n","                                      [0, 0, 1],\n","                                      [0, 1, 0]]\n","                                      \n","        all_X: raw input data and activation output from every layer\n","        \"\"\"\n","        m = Y.shape[0]\n","        #### [TODO 6] START CODE HERE ####\n","        delta_last = (all_X[-1] - Y) / m\n","        grad_last = all_X[-2].T @ delta_last + (self.layers[-1].W * self.reg) / m\n","        #### END CODE HERE ####\n","        return delta_last, grad_last\n","\n","    def backward(self, Y, all_X):\n","        \"\"\"\n","        Backpropagation algorithm to compute gradient at each layer.\n","\n","        Parameters\n","        ----------\n","        Y:  the label, the actual class of the samples. This is one-hot encoding vector.\n","                E.g: [0, 1, 2, 1] => [[1, 0, 0],\n","                                      [0, 1, 0],\n","                                      [0, 0, 1],\n","                                      [0, 1, 0]]\n","        all_X: raw input data and activation output from every layer\n","        \n","        Returns\n","        -------\n","        grad_list: list of gradients we've just computed at each layer.\n","        \"\"\"\n","        \n","        # Compute delta_last and  grad_last from the output\n","        delta_prev, grad_last = self.compute_delta_grad_last(Y, all_X)\n","\n","        grad_list = [grad_last]\n","        for i in range(len(self.layers) - 1)[::-1]:\n","            prev_layer = self.layers[i+1] # previous layer as backward direction\n","            layer = self.layers[i]\n","            X = all_X[i]\n","            #### [TODO 7] START CODE HERE ####\n","            delta_prev = delta_prev @ prev_layer.W.T # dot product of delta_prev and W_prev\n","            grad_W, delta_prev = layer.backward(X, delta_prev)\n","            #### END CODE HERE ####\n","            grad_list.append(grad_W)\n","\n","        grad_list = grad_list[::-1]\n","        return grad_list\n","\n","    def update_weight(self, grad_list):\n","        \"\"\"\n","        Update W by gradient descent using the computed gradient.\n","        \n","        Parameters\n","        ----------\n","        grad_list: (list) list of gradients from all layers that computed from backward function above\n","        learning_rate: (float) learning rate for gradient descent.\n","        \"\"\"\n","        for i, layer in enumerate(self.layers):\n","            grad = grad_list[i]\n","            layer.W = layer.W - self.learning_rate * grad\n","    \n","    def update_weight_momentum(self, grad_list, momentum_rate):\n","        \"\"\"\n","        Update W using gradient descent with momentum\n","\n","        Parameters\n","        ----------\n","        grad_list: (list) list of gradients from all layers that computed from backward function above\n","        learning_rate: (float) learning rate.\n","        momentum_rate: (float) momentum rate.\n","        \"\"\"\n","        if not hasattr(self, \"momentum\"):\n","            self.momentum = [np.zeros_like(grad) for grad in grad_list]\n","            \n","        #### [TODO 8] START CODE HERE ####\n","        v = 0.0\n","        for i, layer in enumerate(self.layers):\n","          grad = grad_list[i]\n","          v = momentum_rate * v + self.learning_rate * grad\n","          layer.W -= v\n","        #### END CODE HERE ####\n","            \n","    def predict(self, X_test):\n","        Y_hat = self.forward(X_test)[-1]\n","        return np.argmax(Y_hat, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gz3F7s_sowbh"},"source":["### Training\n","\n","Sau khi định nghĩa các classes HiddenLayer và NeuralNetwork, chúng ta thực hiện huấn luyện (training) mô hình. Trong bài tập này, 2 kỹ thuật training được giới thiệu:\n","  \n","  + Batch training\n","  + Mini-batch training"]},{"cell_type":"markdown","metadata":{"id":"0FfLh29bo1Cd"},"source":["#### Batch train"]},{"cell_type":"markdown","metadata":{"id":"A0JxaImbVK1N"},"source":["Định nghĩa hàm `batch_train` để  train trên toàn dữ liệu. Có nghĩa là weights `W` trên mạng neural network sẽ được update trên toàn điểm dữ liệu, thay vì ở mỗi batch điểm dữ liệu như là `mini_batch_train`"]},{"cell_type":"code","metadata":{"id":"jFB3Ty-iVK1N"},"source":[" def batch_train(X_train, Y_train, epochs, neural_network, bat=False):\n","    \"\"\"\n","    Using batch train.\n","    \n","    Parameters\n","    ----------\n","    X_train: training data X.\n","    Y_train: training data Y.\n","    epochs: number of iterations that we should use to train.\n","    neural_network: NeuralNetwork object instance above.\n","    \"\"\"\n","    all_loss = []\n","    display_step = 100 if bat else 10\n","    \n","    for e in range(epochs):\n","        all_X = neural_network.forward(X_train)\n","        loss = neural_network.compute_loss(Y_train, all_X[-1])\n","        grad_list = neural_network.backward(Y_train, all_X)\n","        neural_network.update_weight(grad_list)\n","        \n","        all_loss.append(loss)\n","        \n","        if (e+1) % display_step == 0:\n","            display.clear_output(wait=True)\n","            if bat:\n","                y_hat = neural_network.forward(X_train)[-1]\n","                visualize_point(X_train, np.argmax(Y_train,axis=1), y_hat)\n","            plot_loss(all_loss, title=\"Loss epoch %s: %.4f\" % (e+1, loss), color=2)\n","            plt.show()\n","            plt.pause(0.01)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l3sb-LfCVK1P"},"source":["#### \\[TODO 9\\] Mini-batch train\n","Định nghĩa hàm `mini_batch_train` (2đ)\n","\n","**Pseudocode:**\n","\n","```\n","-> For each epoch do:\n","    -> Shuffle data\n","    -> Set initial loss at that epoch equal to 0\n","    -> Calculate number of batches based on batch size and total number of data points\n","    -> For each batch do:\n","        -> all_X := nn.forward() at that batch, Y_hat is equal all_X[-1]\n","        -> compute loss at that batch\n","        -> initial loss += computed loss at that batch\n","        -> grad_list := nn.backward()\n","        -> update weights.\n","```"]},{"cell_type":"code","metadata":{"id":"w_o23rbaVK1P"},"source":[" def minibatch_train(X_train, Y_train, epochs, batch_size, num_class, neural_network):\n","    \"\"\"\n","    Using batch train.\n","    \n","    Parameters\n","    ----------\n","    X_train: training data X.\n","    Y_train: training data Y.\n","    epochs: number of iterations that we should use to train.\n","    batch_size: number of batch at each update.\n","    neural_network: NeuralNetwork object instance above.\n","    \n","    \"\"\"\n","    #### [TODO 9] START CODE HERE ####\n","    iters = len(X_train) // batch_size\n","    all_loss = []\n","    for e in range(epochs):\n","      indices = np.random.permutation(len(X_train))\n","      X_train, Y_train = X_train[indices], Y_train[indices]\n","      loss = 0\n","      for i in range(iters):\n","        batch_x = X_train[i * batch_size : min((i + 1) * batch_size, len(X_train))]\n","        batch_y = Y_train[i * batch_size : min((i + 1) * batch_size, len(Y_train))]\n","        all_X = neural_network.forward(batch_x)\n","        loss += neural_network.compute_loss(batch_y, all_X[-1])\n","        grad_list = neural_network.backward(batch_y, all_X)\n","        neural_network.update_weight(grad_list)\n","        display.clear_output(wait=True)\n","      all_loss.append(loss)\n","      plot_loss(all_loss, title=\"Loss epoch %s: %.4f\" % (e+1, loss), color=2)\n","      plt.show()\n","\n","    #### END CODE HERE ####"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0DirH620RYD"},"source":["### Bat Classification"]},{"cell_type":"markdown","metadata":{"id":"bpnU_FBy1IId"},"source":["#### Hyperparameters"]},{"cell_type":"code","metadata":{"id":"X22sH6ug1LqZ"},"source":["# Thay đổi giá trị của các hyperparameter bên dưới và\n","# quan sát sự thay đổi của loss và quá trình training \n","EPOCHS = 15000\n","LEARNING_RATE = 0.01\n","REG= 1e-5\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mUGCZeKq2M-I"},"source":["#### Định nghĩa hàm `bat_classification`"]},{"cell_type":"code","metadata":{"id":"7R_OW98uVK1R"},"source":["def bat_classification(use_batch_train=True):\n","    # Load data from file\n","    # Make sure that bat.dat is in data/\n","    train_X, train_Y, test_X, test_Y = get_bat_data()\n","    train_X, _, test_X = normalize(train_X, train_X, test_X)    \n","\n","    test_Y  = test_Y.flatten()\n","    train_Y = train_Y.flatten()\n","    num_class = (np.unique(train_Y)).shape[0]\n","\n","    # Pad 1 as the third feature of train_x and test_x\n","    train_X = add_one(train_X) \n","    test_X = add_one(test_X)\n","    \n","    train_Y = create_one_hot(train_Y, num_class)\n","\n","    # Create NN classifier\n","    # Bạn có thể biến đổi thêm/bớt hidden layer, thay đổi hàm activation cho mỗi layer\n","    # và quan sát sự khác biệt trong quá trình train.\n","    net = NeuralNetwork(learning_rate=LEARNING_RATE, num_class=num_class, reg=REG)\n","    net.add_layer(100, 'relu')\n","    net.add_layer(100, 'relu')\n","    net.add_layer(100, 'relu')\n","    net.add_layer(num_class, 'softmax')\n","\n","    if use_batch_train:\n","        #Batch training - train all dataset\n","        batch_train(train_X, train_Y, EPOCHS, net, True)\n","    else:\n","        #Minibatch training - training dataset using Minibatch approach\n","        minibatch_train(train_X, train_Y, EPOCHS, BATCH_SIZE, num_class, net)\n","    metrics = confusion_matrix(test_Y, net.predict(test_X))\n","    print(\"Confusion metrix: \")\n","    print(metrics)\n","    \n","    print(\"Accuracy: \")\n","    print(metrics.trace()/test_Y.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"muLdYJbV2dlM"},"source":["#### Training"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"4xn572XVVK1V","colab":{"base_uri":"https://localhost:8080/","height":756},"executionInfo":{"status":"ok","timestamp":1611319582335,"user_tz":-420,"elapsed":1585154,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}},"outputId":"2acb6d81-9ad0-4ee3-9403-71b567f4b03f"},"source":["bat_classification(use_batch_train=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 864x432 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Confusion metrix: \n","[[1267  220    0]\n"," [  76  851  181]\n"," [   0    1  404]]\n","Accuracy: \n","0.8406666666666667\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dHRIZzum4Q7v"},"source":["### MNIST Classification"]},{"cell_type":"markdown","metadata":{"id":"TAv5PeHq4YRQ"},"source":["#### Hyperparameters"]},{"cell_type":"code","metadata":{"id":"89OE4gdG4bwy"},"source":["# Thay đổi giá trị của các hyperparameter bên dưới và\n","# quan sát sự thay đổi của loss và quá trình training\n","EPOCHS = 300\n","LEARNING_RATE = 0.01\n","REG= 1e-5\n","BATCH_SIZE = 64"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iFDjFonm5buD"},"source":["#### Định nghĩa hàm `mnist_classification`"]},{"cell_type":"code","metadata":{"id":"_EDiru6zVK1S"},"source":["def mnist_classification(use_batch_train=True):\n","    # Load data from file\n","    # Make sure that fashion-mnist/*.gz is in data/\n","    train_X, train_Y, val_X, val_Y, test_X, test_Y = get_mnist_data(1)\n","    train_X, val_X, test_X = normalize(train_X, val_X, test_X)    \n","    \n","    num_class = (np.unique(train_Y)).shape[0]\n","\n","    # Pad 1 as the third feature of train_x and test_x\n","    train_X = add_one(train_X)\n","    val_X = add_one(val_X)\n","    test_X = add_one(test_X)\n","    \n","    train_Y = create_one_hot(train_Y, num_class)\n","    val_Y = create_one_hot(val_Y, num_class)\n","\n","    # Create NN classifier\n","    net = NeuralNetwork(learning_rate=LEARNING_RATE, num_class=num_class, reg=REG)\n","    net.add_layer(128, 'relu')\n","    net.add_layer(256, 'relu')\n","    net.add_layer(100, 'relu')\n","    net.add_layer(64, 'relu')\n","    net.add_layer(num_class, 'softmax')\n","    \n","    if use_batch_train:\n","        #Batch training - train all dataset\n","        batch_train(train_X, train_Y, EPOCHS, net)\n","    else:\n","        #Minibatch training - training dataset using Minibatch approach\n","        minibatch_train(train_X, train_Y, EPOCHS, BATCH_SIZE, num_class, net)\n","    metrics = confusion_matrix(test_Y, net.predict(test_X))\n","    print(\"Confusion metrix: \")\n","    print(metrics)\n","\n","    print(\"Accuracy: \")\n","    print(metrics.trace()/test_Y.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"M9dLdHlaVK1X","colab":{"base_uri":"https://localhost:8080/","height":502},"executionInfo":{"status":"ok","timestamp":1611321326083,"user_tz":-420,"elapsed":1695403,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}},"outputId":"d85fdbcc-f500-49bc-b5ba-352004d98831"},"source":["mnist_classification(use_batch_train=False)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["Confusion metrix: \n","[[823   1  20  23   6   0 117   0   9   1]\n"," [  3 971   1  16   5   0   3   0   1   0]\n"," [ 23   2 825  12  80   1  54   0   3   0]\n"," [ 26   8  18 887  27   0  27   0   6   1]\n"," [  2   1  76  31 830   0  58   0   2   0]\n"," [  1   0   0   0   0 951   0  27   1  20]\n"," [112   0  84  27  69   1 692   0  15   0]\n"," [  0   0   0   0   0  19   0 950   0  31]\n"," [  6   0   6   6   3   2  11   9 956   1]\n"," [  0   0   0   0   0  10   2  34   1 953]]\n","Accuracy: \n","0.8838\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pd7zbo_zVK1Y"},"source":["## II. Thực hiện Deep Neural Network với Tensorflow\n","\n","Phân loại tập dữ liệu Bat và MNIST với tensorflow."]},{"cell_type":"markdown","metadata":{"id":"m51lTqD6rW73"},"source":["### Import các thư viện cần thiết"]},{"cell_type":"code","metadata":{"id":"ozo-4la8VK1Z","executionInfo":{"status":"ok","timestamp":1611368341630,"user_tz":-420,"elapsed":2592,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}}},"source":["import tensorflow as tf\n","L = tf.keras.layers\n"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"7N8tbrbxVK1b","executionInfo":{"status":"ok","timestamp":1611368344239,"user_tz":-420,"elapsed":2131,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}}},"source":["tf.keras.backend.clear_session()"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ljzbayIbrmGw"},"source":["### Cài đặt class `DNNModel`\n","\n","Trong phần này bạn có các TODO sau:"]},{"cell_type":"markdown","metadata":{"id":"YJNmEejir4pM"},"source":["#### \\[TODO 10] Cài đặt kiến trúc mô hình\n","\n","Yêu cầu: xây dựng kiến trúc mạng với `tf.keras.Sequential()` để chồng các hidden layers và output layer với nhau. (1đ)"]},{"cell_type":"markdown","metadata":{"id":"fmKqmC97tttR"},"source":["#### [TODO 11] Cài đặt hàm tính accuracy\n","\n","Cài đặt hàm tính accuracy. (1đ)"]},{"cell_type":"markdown","metadata":{"id":"aDJZnuTEvgzH"},"source":["#### \\[TODO 12\\] Cài đặt hàm train\n","Cài đặt các bước để train mô hình trong class `DNNModel`. (2đ)"]},{"cell_type":"code","metadata":{"id":"gO7GgBTzVK1c","executionInfo":{"status":"ok","timestamp":1611371887740,"user_tz":-420,"elapsed":1309,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}}},"source":["class DNNModel:\n","    def __init__(self, hidden_layers, num_classes, activation, epochs, optimizer):\n","        self.hidden_layers = hidden_layers\n","        self.num_classes = num_classes\n","        self.activation = activation\n","        self.epochs = epochs\n","        self.optimizer = optimizer\n","        \n","        #Hidden layers and output layers are stacked to form a model\n","        self.model = tf.keras.Sequential()\n","        #### [TODO 10] START CODE HERE ####\n","        #Add hidden layers\n","        for nodes in hidden_layers:\n","          self.model.add(tf.keras.layers.Dense(nodes, activation = self.activation))\n","        #Add output layer\n","        self.model.add(tf.keras.layers.Dense(self.num_classes, activation= 'softmax'))\n","        self.model.compile(optimizer = self.optimizer, loss='categorical_crossentropy', metrics = ['accuracy'])\n","        #### END CODE HERE ####\n","\n","    def loss(self, y_hat, y):\n","        \"\"\"\n","        Compute loss function.\n","        \n","        Parameters\n","        ----------\n","        y_hat: output of the last layer (softmax layer).\n","        y: labels/targets in our data.\n","        \n","        Returns\n","        -------\n","        Loss w.r.t y_hat and y. Should be a scalar.\n","        \"\"\"\n","        return tf.reduce_mean(-tf.reduce_sum(y*tf.math.log(y_hat), axis=1), axis=0)\n","\n","    def accuracy(self, y_hat, y):\n","        \"\"\"\n","        Compute accuracy score.\n","        \n","        Parameters\n","        ----------\n","        y_hat: output of the last layer (softmax layer).\n","        y: labels/targets in our data.\n","        \n","        Returns\n","        -------\n","        Accuracy w.r.t y_hat and y. Should be a scalar.\n","        \n","        \"\"\"\n","        #### [TODO 11] START CODE HERE ####\n","        acc, acc_op = tf.metrics.accuracy(labels=tf.argmax(y, 1), predictions=tf.argmax(y_hat,1))\n","        #### END CODE HERE ####\n","        return acc\n","\n","    def train(self, x_train, y_train):\n","        all_loss = []\n","        all_acc = []\n","        for e in range(self.epochs):\n","            #### [TODO 12] START CODE HERE ####\n","            self.model.fit(x_train, y_train)\n","            loss, accuracy = self.model.evaluate(x_train, y_train, verbose = 0)\n","            all_loss.append(loss)\n","            all_acc.append(accuracy)\n","            #### END CODE HERE ####\n","            \n","            print(f\"\\rEpoch: {e}... Training loss: {loss}... Accuracy: {accuracy}\")\n","\n","    def predict(self, inputs):\n","        Y_hat = self.model(inputs)\n","        return tf.argmax(Y_hat, axis=1)"],"execution_count":35,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1H7YE6M4uccG"},"source":["### Bat classification"]},{"cell_type":"code","metadata":{"id":"ZOEopv9gVK1f","executionInfo":{"status":"ok","timestamp":1611371324554,"user_tz":-420,"elapsed":734,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}}},"source":["def tf_bat_classification():\n","     # Load data from file\n","    # Make sure that bat.dat is in data/\n","    train_X, train_Y, test_X, test_Y = get_bat_data()\n","    train_X, _, test_X = normalize(train_X, train_X, test_X)    \n","\n","    test_Y  = test_Y.flatten()\n","    train_Y = train_Y.flatten()\n","    num_class = (np.unique(train_Y)).shape[0]\n","\n","    # Pad 1 as the third feature of train_x and test_x\n","    train_X = add_one(train_X) \n","    test_X = add_one(test_X)\n","    \n","    train_Y = create_one_hot(train_Y, num_class)\n","    \n","    # DNN parameters\n","    hidden_layers = [100, 100, 100]\n","    learning_rate = 0.001\n","    epochs = 200\n","    activation = tf.nn.relu\n","    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)\n","\n","    #Initialize model\n","    dnn = DNNModel(hidden_layers=hidden_layers, num_classes=num_class,\n","                   activation=activation, epochs=epochs, optimizer=optimizer)\n","    #Train\n","    dnn.train(train_X, train_Y)\n","\n","    # TEST\n","    # Confusion matrix\n","    metrics = confusion_matrix(test_Y, dnn.predict(test_X))\n","    print('Confusion matrix:')\n","    print(metrics)\n","    \n","    print(\"Accuracy: \")\n","    print(metrics.trace()/test_Y.shape[0])"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"SLs06JB9VK1i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611371570306,"user_tz":-420,"elapsed":244343,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}},"outputId":"3166d8e9-d530-441f-e832-cbe18b22c751"},"source":["tf_bat_classification()"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Reading bat data...\n","EOF Reached\n","Done reading\n","375/375 [==============================] - 1s 2ms/step - loss: 0.9029 - accuracy: 0.5678\n","Epoch: 0... Training loss: 0.5026988983154297... Accuracy: 0.7715833187103271\n","375/375 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8027\n","Epoch: 1... Training loss: 0.4022652506828308... Accuracy: 0.8386666774749756\n","375/375 [==============================] - 1s 2ms/step - loss: 0.3709 - accuracy: 0.8368\n","Epoch: 2... Training loss: 0.3371357023715973... Accuracy: 0.8535000085830688\n","375/375 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8599\n","Epoch: 3... Training loss: 0.3108006715774536... Accuracy: 0.8640833497047424\n","375/375 [==============================] - 1s 2ms/step - loss: 0.3025 - accuracy: 0.8683\n","Epoch: 4... Training loss: 0.29158255457878113... Accuracy: 0.8682500123977661\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2769 - accuracy: 0.8811\n","Epoch: 5... Training loss: 0.30311381816864014... Accuracy: 0.8568333387374878\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2705 - accuracy: 0.8798\n","Epoch: 6... Training loss: 0.24849972128868103... Accuracy: 0.8991666436195374\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.8802\n","Epoch: 7... Training loss: 0.2238822877407074... Accuracy: 0.903249979019165\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2673 - accuracy: 0.8812\n","Epoch: 8... Training loss: 0.2172291874885559... Accuracy: 0.9076666831970215\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2565 - accuracy: 0.8851\n","Epoch: 9... Training loss: 0.21684899926185608... Accuracy: 0.9075000286102295\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2357 - accuracy: 0.8945\n","Epoch: 10... Training loss: 0.24200351536273956... Accuracy: 0.8896666765213013\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2459 - accuracy: 0.8863\n","Epoch: 11... Training loss: 0.2792647182941437... Accuracy: 0.8744999766349792\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2351 - accuracy: 0.8958\n","Epoch: 12... Training loss: 0.2526416480541229... Accuracy: 0.8859166502952576\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2212 - accuracy: 0.9036\n","Epoch: 13... Training loss: 0.1945890337228775... Accuracy: 0.9140833616256714\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.8997\n","Epoch: 14... Training loss: 0.25551551580429077... Accuracy: 0.8803333044052124\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2152 - accuracy: 0.9054\n","Epoch: 15... Training loss: 0.19983874261379242... Accuracy: 0.9100000262260437\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2226 - accuracy: 0.8992\n","Epoch: 16... Training loss: 0.23135867714881897... Accuracy: 0.8995833396911621\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2149 - accuracy: 0.9050\n","Epoch: 17... Training loss: 0.19953399896621704... Accuracy: 0.9090833067893982\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2087 - accuracy: 0.9062\n","Epoch: 18... Training loss: 0.19080136716365814... Accuracy: 0.9165833592414856\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2075 - accuracy: 0.9087\n","Epoch: 19... Training loss: 0.1861196756362915... Accuracy: 0.918749988079071\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.9040\n","Epoch: 20... Training loss: 0.21768896281719208... Accuracy: 0.9077500104904175\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1973 - accuracy: 0.9152\n","Epoch: 21... Training loss: 0.18145456910133362... Accuracy: 0.9224166870117188\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9182\n","Epoch: 22... Training loss: 0.21684665977954865... Accuracy: 0.9011666774749756\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.9197\n","Epoch: 23... Training loss: 0.17854827642440796... Accuracy: 0.9212499856948853\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9183\n","Epoch: 24... Training loss: 0.17785486578941345... Accuracy: 0.9223333597183228\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.9175\n","Epoch: 25... Training loss: 0.18943779170513153... Accuracy: 0.9165833592414856\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.9179\n","Epoch: 26... Training loss: 0.19021008908748627... Accuracy: 0.9108333587646484\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1725 - accuracy: 0.9259\n","Epoch: 27... Training loss: 0.1629759669303894... Accuracy: 0.9303333163261414\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1837 - accuracy: 0.9207\n","Epoch: 28... Training loss: 0.1395641714334488... Accuracy: 0.9446666836738586\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1747 - accuracy: 0.9244\n","Epoch: 29... Training loss: 0.17042472958564758... Accuracy: 0.9283333420753479\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1680 - accuracy: 0.9280\n","Epoch: 30... Training loss: 0.13465376198291779... Accuracy: 0.9463333487510681\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.9227\n","Epoch: 31... Training loss: 0.15525512397289276... Accuracy: 0.9359166622161865\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.9242\n","Epoch: 32... Training loss: 0.14872533082962036... Accuracy: 0.9350000023841858\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.9218\n","Epoch: 33... Training loss: 0.14392700791358948... Accuracy: 0.9381666779518127\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1732 - accuracy: 0.9243\n","Epoch: 34... Training loss: 0.14549791812896729... Accuracy: 0.9394166469573975\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1708 - accuracy: 0.9262\n","Epoch: 35... Training loss: 0.1467229127883911... Accuracy: 0.9415000081062317\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1678 - accuracy: 0.9270\n","Epoch: 36... Training loss: 0.1442641317844391... Accuracy: 0.9359166622161865\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1617 - accuracy: 0.9303\n","Epoch: 37... Training loss: 0.14927558600902557... Accuracy: 0.9367499947547913\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1683 - accuracy: 0.9264\n","Epoch: 38... Training loss: 0.166714146733284... Accuracy: 0.9233333468437195\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.9270\n","Epoch: 39... Training loss: 0.16459336876869202... Accuracy: 0.9262499809265137\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1690 - accuracy: 0.9277\n","Epoch: 40... Training loss: 0.21146470308303833... Accuracy: 0.9129166603088379\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1688 - accuracy: 0.9260\n","Epoch: 41... Training loss: 0.14964215457439423... Accuracy: 0.9330833554267883\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1725 - accuracy: 0.9259\n","Epoch: 42... Training loss: 0.14653752744197845... Accuracy: 0.9370833039283752\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1558 - accuracy: 0.9311\n","Epoch: 43... Training loss: 0.13544628024101257... Accuracy: 0.940750002861023\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1739 - accuracy: 0.9262\n","Epoch: 44... Training loss: 0.16741490364074707... Accuracy: 0.9225833415985107\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1660 - accuracy: 0.9280\n","Epoch: 45... Training loss: 0.1722719967365265... Accuracy: 0.9201666712760925\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1639 - accuracy: 0.9287\n","Epoch: 46... Training loss: 0.1395220011472702... Accuracy: 0.9402499794960022\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.9266\n","Epoch: 47... Training loss: 0.23058496415615082... Accuracy: 0.8964999914169312\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1628 - accuracy: 0.9300\n","Epoch: 48... Training loss: 0.1705745905637741... Accuracy: 0.924916684627533\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9340\n","Epoch: 49... Training loss: 0.13598503172397614... Accuracy: 0.9419166445732117\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.9223\n","Epoch: 50... Training loss: 0.14707210659980774... Accuracy: 0.937166690826416\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9329\n","Epoch: 51... Training loss: 0.14772798120975494... Accuracy: 0.937250018119812\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1533 - accuracy: 0.9348\n","Epoch: 52... Training loss: 0.15100589394569397... Accuracy: 0.9393333196640015\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.9237\n","Epoch: 53... Training loss: 0.19572745263576508... Accuracy: 0.9123333096504211\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1470 - accuracy: 0.9356\n","Epoch: 54... Training loss: 0.18657541275024414... Accuracy: 0.9169999957084656\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1658 - accuracy: 0.9261\n","Epoch: 55... Training loss: 0.13887041807174683... Accuracy: 0.940833330154419\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1523 - accuracy: 0.9358\n","Epoch: 56... Training loss: 0.16491922736167908... Accuracy: 0.9254166483879089\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9302\n","Epoch: 57... Training loss: 0.1400776505470276... Accuracy: 0.937583327293396\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9353\n","Epoch: 58... Training loss: 0.13898159563541412... Accuracy: 0.9434999823570251\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.9242\n","Epoch: 59... Training loss: 0.15576709806919098... Accuracy: 0.9320833086967468\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1501 - accuracy: 0.9381\n","Epoch: 60... Training loss: 0.14358195662498474... Accuracy: 0.937166690826416\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1572 - accuracy: 0.9339\n","Epoch: 61... Training loss: 0.16024890542030334... Accuracy: 0.9298333525657654\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1556 - accuracy: 0.9342\n","Epoch: 62... Training loss: 0.1347353160381317... Accuracy: 0.9412500262260437\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1598 - accuracy: 0.9337\n","Epoch: 63... Training loss: 0.11977721005678177... Accuracy: 0.9510833621025085\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.9348\n","Epoch: 64... Training loss: 0.15139763057231903... Accuracy: 0.9327499866485596\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1571 - accuracy: 0.9297\n","Epoch: 65... Training loss: 0.13768334686756134... Accuracy: 0.9412500262260437\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1585 - accuracy: 0.9338\n","Epoch: 66... Training loss: 0.14290593564510345... Accuracy: 0.9395833611488342\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.9264\n","Epoch: 67... Training loss: 0.1589781939983368... Accuracy: 0.9278333187103271\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1477 - accuracy: 0.9359\n","Epoch: 68... Training loss: 0.12011849880218506... Accuracy: 0.949833333492279\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1573 - accuracy: 0.9332\n","Epoch: 69... Training loss: 0.18157918751239777... Accuracy: 0.9204166531562805\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1580 - accuracy: 0.9316\n","Epoch: 70... Training loss: 0.1263227015733719... Accuracy: 0.9447500109672546\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1462 - accuracy: 0.9358\n","Epoch: 71... Training loss: 0.18571259081363678... Accuracy: 0.918833315372467\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1481 - accuracy: 0.9357\n","Epoch: 72... Training loss: 0.1366899609565735... Accuracy: 0.9402499794960022\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9307\n","Epoch: 73... Training loss: 0.15202480554580688... Accuracy: 0.9325833320617676\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1522 - accuracy: 0.9369\n","Epoch: 74... Training loss: 0.12621432542800903... Accuracy: 0.9480000138282776\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1427 - accuracy: 0.9383\n","Epoch: 75... Training loss: 0.17482778429985046... Accuracy: 0.9241666793823242\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1554 - accuracy: 0.9327\n","Epoch: 76... Training loss: 0.12425868958234787... Accuracy: 0.9449999928474426\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1464 - accuracy: 0.9373\n","Epoch: 77... Training loss: 0.13006696105003357... Accuracy: 0.9453333616256714\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1461 - accuracy: 0.9364\n","Epoch: 78... Training loss: 0.13405103981494904... Accuracy: 0.9409166574478149\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1511 - accuracy: 0.9349\n","Epoch: 79... Training loss: 0.13803192973136902... Accuracy: 0.9399999976158142\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1466 - accuracy: 0.9357\n","Epoch: 80... Training loss: 0.11598777025938034... Accuracy: 0.9509999752044678\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9343\n","Epoch: 81... Training loss: 0.12468206137418747... Accuracy: 0.9431666731834412\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9362\n","Epoch: 82... Training loss: 0.13311061263084412... Accuracy: 0.9425833225250244\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9352\n","Epoch: 83... Training loss: 0.12803293764591217... Accuracy: 0.9453333616256714\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1562 - accuracy: 0.9322\n","Epoch: 84... Training loss: 0.12240487337112427... Accuracy: 0.949916660785675\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1539 - accuracy: 0.9316\n","Epoch: 85... Training loss: 0.1283159852027893... Accuracy: 0.9451666474342346\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1475 - accuracy: 0.9337\n","Epoch: 86... Training loss: 0.14311832189559937... Accuracy: 0.9381666779518127\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1420 - accuracy: 0.9378\n","Epoch: 87... Training loss: 0.17094890773296356... Accuracy: 0.9254999756813049\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1490 - accuracy: 0.9336\n","Epoch: 88... Training loss: 0.17321042716503143... Accuracy: 0.9234166741371155\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1531 - accuracy: 0.9353\n","Epoch: 89... Training loss: 0.14933811128139496... Accuracy: 0.9358333349227905\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1399 - accuracy: 0.9399\n","Epoch: 90... Training loss: 0.13911865651607513... Accuracy: 0.937666654586792\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1507 - accuracy: 0.9320\n","Epoch: 91... Training loss: 0.13548047840595245... Accuracy: 0.9418333172798157\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1555 - accuracy: 0.9310\n","Epoch: 92... Training loss: 0.12752598524093628... Accuracy: 0.9440833330154419\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1426 - accuracy: 0.9388\n","Epoch: 93... Training loss: 0.14034578204154968... Accuracy: 0.940833330154419\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1525 - accuracy: 0.9341\n","Epoch: 94... Training loss: 0.13558819890022278... Accuracy: 0.9368333220481873\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1419 - accuracy: 0.9397\n","Epoch: 95... Training loss: 0.15674075484275818... Accuracy: 0.9300833344459534\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1419 - accuracy: 0.9379\n","Epoch: 96... Training loss: 0.24711911380290985... Accuracy: 0.9049999713897705\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1459 - accuracy: 0.9362\n","Epoch: 97... Training loss: 0.1468583047389984... Accuracy: 0.9353333115577698\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1523 - accuracy: 0.9352\n","Epoch: 98... Training loss: 0.1436619609594345... Accuracy: 0.9379166960716248\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1544 - accuracy: 0.9328\n","Epoch: 99... Training loss: 0.17037281394004822... Accuracy: 0.921750009059906\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9373\n","Epoch: 100... Training loss: 0.2050742357969284... Accuracy: 0.9123333096504211\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1475 - accuracy: 0.9337\n","Epoch: 101... Training loss: 0.1250738650560379... Accuracy: 0.9438333511352539\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1427 - accuracy: 0.9374\n","Epoch: 102... Training loss: 0.16172201931476593... Accuracy: 0.9283333420753479\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1410 - accuracy: 0.9362\n","Epoch: 103... Training loss: 0.13043099641799927... Accuracy: 0.9428333044052124\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1481 - accuracy: 0.9348\n","Epoch: 104... Training loss: 0.12304792553186417... Accuracy: 0.9458333253860474\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1413 - accuracy: 0.9397\n","Epoch: 105... Training loss: 0.11186883598566055... Accuracy: 0.953499972820282\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1378 - accuracy: 0.9415\n","Epoch: 106... Training loss: 0.12451464682817459... Accuracy: 0.9457499980926514\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1416 - accuracy: 0.9386\n","Epoch: 107... Training loss: 0.14877881109714508... Accuracy: 0.934166669845581\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1489 - accuracy: 0.9372\n","Epoch: 108... Training loss: 0.13194511830806732... Accuracy: 0.9422500133514404\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1407 - accuracy: 0.9413\n","Epoch: 109... Training loss: 0.1302948147058487... Accuracy: 0.9399166703224182\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1429 - accuracy: 0.9392\n","Epoch: 110... Training loss: 0.14957548677921295... Accuracy: 0.9323333501815796\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9392\n","Epoch: 111... Training loss: 0.15548421442508698... Accuracy: 0.9357500076293945\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1541 - accuracy: 0.9320\n","Epoch: 112... Training loss: 0.14770792424678802... Accuracy: 0.9368333220481873\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9382\n","Epoch: 113... Training loss: 0.12096986174583435... Accuracy: 0.9487500190734863\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9389\n","Epoch: 114... Training loss: 0.10661698132753372... Accuracy: 0.9576666951179504\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1365 - accuracy: 0.9385\n","Epoch: 115... Training loss: 0.13530325889587402... Accuracy: 0.940833330154419\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1422 - accuracy: 0.9379\n","Epoch: 116... Training loss: 0.1394961178302765... Accuracy: 0.9380000233650208\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1333 - accuracy: 0.9442\n","Epoch: 117... Training loss: 0.17021383345127106... Accuracy: 0.924833357334137\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1432 - accuracy: 0.9406\n","Epoch: 118... Training loss: 0.10611889511346817... Accuracy: 0.9554166793823242\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1445 - accuracy: 0.9373\n","Epoch: 119... Training loss: 0.13864317536354065... Accuracy: 0.9410833120346069\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1331 - accuracy: 0.9425\n","Epoch: 120... Training loss: 0.18660229444503784... Accuracy: 0.9224166870117188\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9383\n","Epoch: 121... Training loss: 0.19680294394493103... Accuracy: 0.9127500057220459\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9376\n","Epoch: 122... Training loss: 0.16640006005764008... Accuracy: 0.9257500171661377\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9339\n","Epoch: 123... Training loss: 0.12010438740253448... Accuracy: 0.9469166398048401\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1369 - accuracy: 0.9418\n","Epoch: 124... Training loss: 0.11941926926374435... Accuracy: 0.9475833177566528\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1393 - accuracy: 0.9370\n","Epoch: 125... Training loss: 0.1377010941505432... Accuracy: 0.9419166445732117\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1335 - accuracy: 0.9396\n","Epoch: 126... Training loss: 0.1449153572320938... Accuracy: 0.940750002861023\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9363\n","Epoch: 127... Training loss: 0.11696045845746994... Accuracy: 0.9505833387374878\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1439 - accuracy: 0.9369\n","Epoch: 128... Training loss: 0.1514088213443756... Accuracy: 0.9307500123977661\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1423 - accuracy: 0.9380\n","Epoch: 129... Training loss: 0.19323430955410004... Accuracy: 0.9185000061988831\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1397 - accuracy: 0.9414\n","Epoch: 130... Training loss: 0.12210442125797272... Accuracy: 0.9495833516120911\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1350 - accuracy: 0.9408\n","Epoch: 131... Training loss: 0.16409893333911896... Accuracy: 0.9308333396911621\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1331 - accuracy: 0.9419\n","Epoch: 132... Training loss: 0.10888615250587463... Accuracy: 0.9554166793823242\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9372\n","Epoch: 133... Training loss: 0.1296416074037552... Accuracy: 0.9475833177566528\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1343 - accuracy: 0.9430\n","Epoch: 134... Training loss: 0.12437893450260162... Accuracy: 0.9449999928474426\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1310 - accuracy: 0.9424\n","Epoch: 135... Training loss: 0.10124454647302628... Accuracy: 0.9581666588783264\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1296 - accuracy: 0.9445\n","Epoch: 136... Training loss: 0.1396828442811966... Accuracy: 0.9409166574478149\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9383\n","Epoch: 137... Training loss: 0.12854383885860443... Accuracy: 0.9432500004768372\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1460 - accuracy: 0.9362\n","Epoch: 138... Training loss: 0.12174666672945023... Accuracy: 0.9475833177566528\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1385 - accuracy: 0.9396\n","Epoch: 139... Training loss: 0.11857813596725464... Accuracy: 0.9476666450500488\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1380 - accuracy: 0.9396\n","Epoch: 140... Training loss: 0.12584300339221954... Accuracy: 0.9434166550636292\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9401\n","Epoch: 141... Training loss: 0.11692836135625839... Accuracy: 0.9504166841506958\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1290 - accuracy: 0.9438\n","Epoch: 142... Training loss: 0.1251135915517807... Accuracy: 0.9463333487510681\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1326 - accuracy: 0.9424\n","Epoch: 143... Training loss: 0.13650289177894592... Accuracy: 0.940666675567627\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1353 - accuracy: 0.9417\n","Epoch: 144... Training loss: 0.11005749553442001... Accuracy: 0.9514999985694885\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1273 - accuracy: 0.9455\n","Epoch: 145... Training loss: 0.1256689727306366... Accuracy: 0.9435833096504211\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1325 - accuracy: 0.9423\n","Epoch: 146... Training loss: 0.10284532606601715... Accuracy: 0.9558333158493042\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1431 - accuracy: 0.9365\n","Epoch: 147... Training loss: 0.11860047280788422... Accuracy: 0.9507499933242798\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1294 - accuracy: 0.9441\n","Epoch: 148... Training loss: 0.15930311381816864... Accuracy: 0.9280833601951599\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1315 - accuracy: 0.9440\n","Epoch: 149... Training loss: 0.11614835262298584... Accuracy: 0.949833333492279\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1429 - accuracy: 0.9392\n","Epoch: 150... Training loss: 0.15377366542816162... Accuracy: 0.9309166669845581\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1280 - accuracy: 0.9448\n","Epoch: 151... Training loss: 0.11429738253355026... Accuracy: 0.9514166712760925\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1320 - accuracy: 0.9440\n","Epoch: 152... Training loss: 0.1352335810661316... Accuracy: 0.9400833249092102\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1286 - accuracy: 0.9436\n","Epoch: 153... Training loss: 0.11826252937316895... Accuracy: 0.9477499723434448\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1362 - accuracy: 0.9402\n","Epoch: 154... Training loss: 0.12816710770130157... Accuracy: 0.9432500004768372\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1351 - accuracy: 0.9408\n","Epoch: 155... Training loss: 0.18038193881511688... Accuracy: 0.92208331823349\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1315 - accuracy: 0.9424\n","Epoch: 156... Training loss: 0.10769825428724289... Accuracy: 0.95291668176651\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1270 - accuracy: 0.9471\n","Epoch: 157... Training loss: 0.1482415348291397... Accuracy: 0.9348333477973938\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1274 - accuracy: 0.9454\n","Epoch: 158... Training loss: 0.14190126955509186... Accuracy: 0.9350000023841858\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1321 - accuracy: 0.9442\n","Epoch: 159... Training loss: 0.10680948942899704... Accuracy: 0.956333339214325\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1302 - accuracy: 0.9446\n","Epoch: 160... Training loss: 0.10733219236135483... Accuracy: 0.9541666507720947\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1348 - accuracy: 0.9413\n","Epoch: 161... Training loss: 0.1596926748752594... Accuracy: 0.9291666746139526\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1271 - accuracy: 0.9443\n","Epoch: 162... Training loss: 0.12004856020212173... Accuracy: 0.9456666707992554\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.9414\n","Epoch: 163... Training loss: 0.10933228582143784... Accuracy: 0.9536666870117188\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9406\n","Epoch: 164... Training loss: 0.17527136206626892... Accuracy: 0.9259999990463257\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1303 - accuracy: 0.9408\n","Epoch: 165... Training loss: 0.11503916233778... Accuracy: 0.9518333077430725\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1389 - accuracy: 0.9383\n","Epoch: 166... Training loss: 0.10615038871765137... Accuracy: 0.9555833339691162\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1309 - accuracy: 0.9418\n","Epoch: 167... Training loss: 0.14186324179172516... Accuracy: 0.9390833377838135\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1341 - accuracy: 0.9405\n","Epoch: 168... Training loss: 0.12717093527317047... Accuracy: 0.9464166760444641\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1322 - accuracy: 0.9446\n","Epoch: 169... Training loss: 0.1465442031621933... Accuracy: 0.9320833086967468\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1308 - accuracy: 0.9434\n","Epoch: 170... Training loss: 0.13229845464229584... Accuracy: 0.9420833587646484\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1364 - accuracy: 0.9408\n","Epoch: 171... Training loss: 0.11366642266511917... Accuracy: 0.9520833492279053\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1236 - accuracy: 0.9477\n","Epoch: 172... Training loss: 0.10694806277751923... Accuracy: 0.953166663646698\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1313 - accuracy: 0.9436\n","Epoch: 173... Training loss: 0.14975984394550323... Accuracy: 0.934499979019165\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1302 - accuracy: 0.9446\n","Epoch: 174... Training loss: 0.1261693388223648... Accuracy: 0.9476666450500488\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1363 - accuracy: 0.9405\n","Epoch: 175... Training loss: 0.16249020397663116... Accuracy: 0.9402499794960022\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1283 - accuracy: 0.9448\n","Epoch: 176... Training loss: 0.11791010200977325... Accuracy: 0.9447500109672546\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1292 - accuracy: 0.9430\n","Epoch: 177... Training loss: 0.1052006334066391... Accuracy: 0.9555833339691162\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1254 - accuracy: 0.9428\n","Epoch: 178... Training loss: 0.18165455758571625... Accuracy: 0.9197499752044678\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1278 - accuracy: 0.9430\n","Epoch: 179... Training loss: 0.11200789362192154... Accuracy: 0.9526666402816772\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1337 - accuracy: 0.9429\n","Epoch: 180... Training loss: 0.11220985651016235... Accuracy: 0.9505000114440918\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1321 - accuracy: 0.9423\n","Epoch: 181... Training loss: 0.12642674148082733... Accuracy: 0.9449166655540466\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1255 - accuracy: 0.9449\n","Epoch: 182... Training loss: 0.10765758156776428... Accuracy: 0.9508333206176758\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1289 - accuracy: 0.9436\n","Epoch: 183... Training loss: 0.1349097192287445... Accuracy: 0.9395833611488342\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1292 - accuracy: 0.9432\n","Epoch: 184... Training loss: 0.11838414520025253... Accuracy: 0.9465000033378601\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1342 - accuracy: 0.9399\n","Epoch: 185... Training loss: 0.12551219761371613... Accuracy: 0.9452499747276306\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1280 - accuracy: 0.9438\n","Epoch: 186... Training loss: 0.11849252134561539... Accuracy: 0.9465833306312561\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1283 - accuracy: 0.9442\n","Epoch: 187... Training loss: 0.11115286499261856... Accuracy: 0.9523333311080933\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.9474\n","Epoch: 188... Training loss: 0.09977146238088608... Accuracy: 0.9595000147819519\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1332 - accuracy: 0.9409\n","Epoch: 189... Training loss: 0.1340993493795395... Accuracy: 0.9434166550636292\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1297 - accuracy: 0.9433\n","Epoch: 190... Training loss: 0.1299317628145218... Accuracy: 0.9440000057220459\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1292 - accuracy: 0.9447\n","Epoch: 191... Training loss: 0.1459522843360901... Accuracy: 0.9388333559036255\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9408\n","Epoch: 192... Training loss: 0.12238186597824097... Accuracy: 0.9480000138282776\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1245 - accuracy: 0.9452\n","Epoch: 193... Training loss: 0.105886310338974... Accuracy: 0.9546666741371155\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1221 - accuracy: 0.9468\n","Epoch: 194... Training loss: 0.1615518480539322... Accuracy: 0.9260833263397217\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1290 - accuracy: 0.9440\n","Epoch: 195... Training loss: 0.15012584626674652... Accuracy: 0.9325833320617676\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1255 - accuracy: 0.9460\n","Epoch: 196... Training loss: 0.12222396582365036... Accuracy: 0.9455833435058594\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1246 - accuracy: 0.9453\n","Epoch: 197... Training loss: 0.11730676144361496... Accuracy: 0.9492499828338623\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9443\n","Epoch: 198... Training loss: 0.10818828642368317... Accuracy: 0.9509999752044678\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1226 - accuracy: 0.9460\n","Epoch: 199... Training loss: 0.10162297636270523... Accuracy: 0.9559166431427002\n","Confusion matrix:\n","[[1438   49    0]\n"," [  32 1036   40]\n"," [   0   24  381]]\n","Accuracy: \n","0.9516666666666667\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ywAI6WfHujxe"},"source":["### MNIST Classification"]},{"cell_type":"code","metadata":{"id":"15_FXzMGVK1j","executionInfo":{"status":"ok","timestamp":1611371892061,"user_tz":-420,"elapsed":1784,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}}},"source":["def tf_mnist_classification():\n","    # Load data from file\n","    # Make sure that fashion-mnist/*.gz is in data/\n","    train_X, train_Y, val_X, val_Y, test_X, test_Y = get_mnist_data(1)\n","    train_X, val_X, test_X = normalize(train_X, val_X, test_X)    \n","    \n","    num_class = (np.unique(train_Y)).shape[0]\n","\n","    # Pad 1 as the third feature of train_x and test_x\n","    train_X = add_one(train_X)\n","    val_X = add_one(val_X)\n","    test_X = add_one(test_X)\n","    \n","    train_Y = create_one_hot(train_Y, num_class)\n","    val_Y = create_one_hot(val_Y, num_class)\n","\n","    # Define hyper-parameters and train-related parameters\n","    hidden_layers = [128, 256, 100, 64]\n","    learning_rate = 0.001\n","    epochs = 50\n","    activation = tf.nn.relu\n","    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","\n","    #Initialize model\n","    dnn = DNNModel(hidden_layers=hidden_layers, num_classes=num_class,\n","                   activation=activation, epochs=epochs, optimizer=optimizer)\n","    #Train\n","    dnn.train(train_X, train_Y)\n","\n","    # TEST\n","    # Confusion matrix\n","    metrics = confusion_matrix(test_Y, dnn.predict(test_X))\n","    print('Confusion matrix:')\n","    print(metrics)\n","    print(\"Accuracy: \")\n","    print(metrics.trace()/test_Y.shape[0])"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vv9L55P8VK1l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611372218631,"user_tz":-420,"elapsed":325537,"user":{"displayName":"Nhat Khang Ngo","photoUrl":"","userId":"09155378841962883783"}},"outputId":"e23b853c-b70c-48f3-e6c6-be12c5474a75"},"source":["tf_mnist_classification()"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Reading fashion MNIST data...\n","Done reading\n","1563/1563 [==============================] - 4s 2ms/step - loss: 0.6092 - accuracy: 0.7805\n","Epoch: 0... Training loss: 0.3948735296726227... Accuracy: 0.8555399775505066\n","1563/1563 [==============================] - 4s 2ms/step - loss: 0.3673 - accuracy: 0.8645\n","Epoch: 1... Training loss: 0.3356882333755493... Accuracy: 0.8748599886894226\n","1563/1563 [==============================] - 4s 2ms/step - loss: 0.3299 - accuracy: 0.8769\n","Epoch: 2... Training loss: 0.31661152839660645... Accuracy: 0.8827400207519531\n","1563/1563 [==============================] - 4s 2ms/step - loss: 0.3067 - accuracy: 0.8866\n","Epoch: 3... Training loss: 0.2851766049861908... Accuracy: 0.8959400057792664\n","1563/1563 [==============================] - 4s 2ms/step - loss: 0.2899 - accuracy: 0.8922\n","Epoch: 4... Training loss: 0.2514333128929138... Accuracy: 0.9023000001907349\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.2703 - accuracy: 0.8988\n","Epoch: 5... Training loss: 0.25191405415534973... Accuracy: 0.9061800241470337\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.2588 - accuracy: 0.9040\n","Epoch: 6... Training loss: 0.2190251350402832... Accuracy: 0.9184799790382385\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.2434 - accuracy: 0.9077\n","Epoch: 7... Training loss: 0.2241906374692917... Accuracy: 0.9157400131225586\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.2331 - accuracy: 0.9114\n","Epoch: 8... Training loss: 0.20127281546592712... Accuracy: 0.9251599907875061\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.2245 - accuracy: 0.9149\n","Epoch: 9... Training loss: 0.19776614010334015... Accuracy: 0.9236400127410889\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.2184 - accuracy: 0.9189\n","Epoch: 10... Training loss: 0.1949721872806549... Accuracy: 0.9251800179481506\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.2027 - accuracy: 0.9221\n","Epoch: 11... Training loss: 0.17898237705230713... Accuracy: 0.9323999881744385\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.2018 - accuracy: 0.9241\n","Epoch: 12... Training loss: 0.1862349957227707... Accuracy: 0.9263799786567688\n","1563/1563 [==============================] - 4s 2ms/step - loss: 0.1922 - accuracy: 0.9276\n","Epoch: 13... Training loss: 0.18106523156166077... Accuracy: 0.9316400289535522\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1822 - accuracy: 0.9309\n","Epoch: 14... Training loss: 0.18342824280261993... Accuracy: 0.9278200268745422\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1790 - accuracy: 0.9323\n","Epoch: 15... Training loss: 0.16666285693645477... Accuracy: 0.9368600249290466\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1727 - accuracy: 0.9339\n","Epoch: 16... Training loss: 0.16411490738391876... Accuracy: 0.937720000743866\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1627 - accuracy: 0.9376\n","Epoch: 17... Training loss: 0.15253901481628418... Accuracy: 0.9421200156211853\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1582 - accuracy: 0.9388\n","Epoch: 18... Training loss: 0.13412556052207947... Accuracy: 0.9478600025177002\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1574 - accuracy: 0.9410\n","Epoch: 19... Training loss: 0.197087362408638... Accuracy: 0.9336199760437012\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1506 - accuracy: 0.9432\n","Epoch: 20... Training loss: 0.12913073599338531... Accuracy: 0.9506800174713135\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1449 - accuracy: 0.9441\n","Epoch: 21... Training loss: 0.13411681354045868... Accuracy: 0.9516400098800659\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1424 - accuracy: 0.9468\n","Epoch: 22... Training loss: 0.12432859092950821... Accuracy: 0.9528200030326843\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1401 - accuracy: 0.9475\n","Epoch: 23... Training loss: 0.14064264297485352... Accuracy: 0.9462400078773499\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1351 - accuracy: 0.9482\n","Epoch: 24... Training loss: 0.12373420596122742... Accuracy: 0.9534599781036377\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1306 - accuracy: 0.9497\n","Epoch: 25... Training loss: 0.11480426043272018... Accuracy: 0.9559000134468079\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1272 - accuracy: 0.9522\n","Epoch: 26... Training loss: 0.10434599965810776... Accuracy: 0.9610999822616577\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1230 - accuracy: 0.9534\n","Epoch: 27... Training loss: 0.11036761850118637... Accuracy: 0.9588000178337097\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1214 - accuracy: 0.9541\n","Epoch: 28... Training loss: 0.10730470716953278... Accuracy: 0.960319995880127\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1199 - accuracy: 0.9551\n","Epoch: 29... Training loss: 0.09958072006702423... Accuracy: 0.9628000259399414\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1130 - accuracy: 0.9573\n","Epoch: 30... Training loss: 0.1001010611653328... Accuracy: 0.9615600109100342\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1109 - accuracy: 0.9580\n","Epoch: 31... Training loss: 0.13294252753257751... Accuracy: 0.9502999782562256\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1113 - accuracy: 0.9584\n","Epoch: 32... Training loss: 0.09536212682723999... Accuracy: 0.9649999737739563\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1071 - accuracy: 0.9599\n","Epoch: 33... Training loss: 0.09478336572647095... Accuracy: 0.9638199806213379\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1006 - accuracy: 0.9607\n","Epoch: 34... Training loss: 0.10633257776498795... Accuracy: 0.9620199799537659\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1075 - accuracy: 0.9604\n","Epoch: 35... Training loss: 0.1031152531504631... Accuracy: 0.9621000289916992\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0987 - accuracy: 0.9629\n","Epoch: 36... Training loss: 0.08569462597370148... Accuracy: 0.9694399833679199\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.1007 - accuracy: 0.9621\n","Epoch: 37... Training loss: 0.09821364283561707... Accuracy: 0.9640399813652039\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0995 - accuracy: 0.9630\n","Epoch: 38... Training loss: 0.08566530048847198... Accuracy: 0.9672399759292603\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0940 - accuracy: 0.9644\n","Epoch: 39... Training loss: 0.0882500484585762... Accuracy: 0.9667400121688843\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0900 - accuracy: 0.9664\n","Epoch: 40... Training loss: 0.08891065418720245... Accuracy: 0.9658200144767761\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0951 - accuracy: 0.9652\n","Epoch: 41... Training loss: 0.08404769748449326... Accuracy: 0.966920018196106\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0900 - accuracy: 0.9663\n","Epoch: 42... Training loss: 0.06759677082300186... Accuracy: 0.9750400185585022\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0918 - accuracy: 0.9664\n","Epoch: 43... Training loss: 0.07895712554454803... Accuracy: 0.9696999788284302\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0834 - accuracy: 0.9689\n","Epoch: 44... Training loss: 0.07871321588754654... Accuracy: 0.9694399833679199\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0875 - accuracy: 0.9681\n","Epoch: 45... Training loss: 0.0714825764298439... Accuracy: 0.9743199944496155\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0840 - accuracy: 0.9701\n","Epoch: 46... Training loss: 0.05741044878959656... Accuracy: 0.978600025177002\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0797 - accuracy: 0.9707\n","Epoch: 47... Training loss: 0.06907539069652557... Accuracy: 0.9753999710083008\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0815 - accuracy: 0.9699\n","Epoch: 48... Training loss: 0.0930376872420311... Accuracy: 0.9729200005531311\n","1563/1563 [==============================] - 4s 3ms/step - loss: 0.0867 - accuracy: 0.9694\n","Epoch: 49... Training loss: 0.07005195319652557... Accuracy: 0.9745200276374817\n","Confusion matrix:\n","[[836   0  14  19   1   1 120   0   9   0]\n"," [  6 966   3  14   5   0   5   0   0   1]\n"," [ 15   1 815   9  87   0  71   0   2   0]\n"," [ 20   5  14 856  53   0  49   0   3   0]\n"," [  1   2  94  19 832   0  49   0   3   0]\n"," [  0   0   1   1   0 957   0  21   3  17]\n"," [103   2  83  18  79   0 708   0   7   0]\n"," [  0   0   0   0   0  15   0 944   0  41]\n"," [  3   0   2   1   1   1   8   3 981   0]\n"," [  1   0   0   0   0   7   0  25   0 967]]\n","Accuracy: \n","0.8862\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e2V4EFbK6qqR"},"source":["# III. Nộp bài\n","Sau khi thực hiện xong các bạn cần upload file bài làm .ipynb theo hướng dẫn ở [form này](https://forms.gle/yUdsDcYV6Z5eFFr89)."]},{"cell_type":"markdown","metadata":{"id":"A796xi6AaXwy"},"source":["## IV. Thang điểm\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ojErsXU5xX6u"},"source":["| TODO  | Điểm  |   |   |   |\n","|---|---|---|---|---|\n","|\\[TODO 1\\] Cài đặt các hàm activation   |  1 |   |   |   |\n","|\\[TODO 2\\] Hàm `forward`/`HiddenLayer` | 1  |   |   |   |\n","|\\[TODO 3\\] Hàm `backward`/`HiddenLayer`  | 2  |   |   |   |\n","|\\[TODO 4\\] Hàm `forward`/`NeuralNetwork`  | 0.5  |   |   |   |\n","|\\[TODO 5\\] Hàm `compute_loss`/`NeuralNetwork`  | 1.5  |   |   |   |\n","|\\[TODO 6\\] Hàm `compute_delta_grad_last`/`NeuralNetwork`  | 1  |   |   |   |\n","|\\[TODO 7\\] Hàm `backward`/`NeuralNetwork`  | 1  |   |   |   |\n","|\\[TODO 8\\] Hàm `update_weight_momentum`/`NeuralNetwork`  | 1  |   |   |   |\n","|\\[TODO 9\\] Hàm `minibatch_train`  | 2  |   |   |   |\n","|\\[TODO 10\\] Cài đặt kiến trúc Neural network sử dụng tensorflow  | 1  |   |   |   |\n","|\\[TODO 11\\] Cài đặt hàm tính accuracy  | 1  |   |   |   |\n","|\\[TODO 12\\] Cài đặt hàm train trong class `DNNModel`  | 2  |   |   |   |\n","|**Tổng**| **15**  |   |   |   |"]},{"cell_type":"markdown","metadata":{"id":"UWgbEVveBxji"},"source":["## Author: Giang Tran, Hoa Nguyen"]},{"cell_type":"code","metadata":{"id":"AnHV18q7eVgA"},"source":[""],"execution_count":null,"outputs":[]}]}